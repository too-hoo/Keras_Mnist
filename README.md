# 深度学习: 使用Keras搭建深度学习网络做手写数字识别

## 总结

1、深度学习值得投入时间去学习，可以通过查询keras的API进行更多的知识学习

2、在这个过程里面，只是使用了LeNet的网络模型，实际上AlexNet，VGG，GoogleNet和ResNet都是基于CNN的网络结构。在CNN网络中包含了卷积层、池化层和全连接层。

3、一个基于CNN的深度学习网络通常是几组卷积层之后，再连接多个全连接层，最后再连接Output全连接层，而每组的卷积层收拾“卷积层+->池化层？”的结构。

4、另外，通过今上面的项目可以知道卷积在图像领域中的应用。例如对海报进行了一个3 * 3的卷积核操作，可以看到卷积之后得到的图像是原图像的某种特征的提取。在实际的卷积层中，会包含多个卷积核，对原图像在不同的特征上进行提取。通过多个卷积层的操作，可以在更高的维度上对图像特征进一步提取，这样可以让机器在不同的层次，不同的维度理解图像的特征。

5、另外在Keras使用中，我们能看到与sklearn中的机器学习算法使用不同。需要手动对网络模型中的层进行配置，把创建好的层添加到模型中，然后对模型中使用的损失函数和优化器进行配置,最后就可以对它进行训练和预测了。

6、使用Keras实现手写数字的识别
- CNN网络
    - 卷积操作的原理
        - 第一步，需要将卷积核翻转180度
        - 第二步,将卷积核的第一个元素，对准矩阵X左上角的第一个元素，然后对应元素相乘，然后再相加
        - 第三步，每个元素都按照第二步的计算过程，可以得到最终的矩阵结果
    - 练习：对海报进行3 * 3的卷积操作
    - 激活函数：将线性数值映射到非线性空间中，让神经网络的表达能力更加强大
    - 池化层：通常是在两个卷积层之间，它相当于对神经元的数据进行降维处理，这样我们就能通过池化层降维降低整体的计算量。
- LeNet和AlexNet网络
    - LeNet和AlexNet的参数对比
    - LeNet：输入层->C1卷积层->S2池化层->C3卷积层->S4池化层->C5卷积层->F6全连接层->Output全连接层，对应的Output输出类别数为10
    - AlexNet：输入层->(C1卷积层->池化层)->(C2卷积层->池化层)->C3卷积层->C4卷积层-（C5池化层->池化层）->全连接层->全连接层->Output全连接层
    - 通用网络结构：输出层->(卷积层+—>池化层？) +->全连接层+->Output全连接层
- 常用的深度学习框架的对比
    - GitHub上最热的3个框架：TensorFlow，Keras和Caffe
    - Keras：适合初学者，基于TensorFlow或者Theano为后端，在他们的基础上提供的封装接口，更加方便我们使用
- 用Keras做Mnist手写数字的识别
    - 安装工具包
        - keras
        - tensorflow
        - numpy
    - 模型创建
        - 序贯模型：Sequential
        - 二维卷积层：Conv2D(filters,kernel_size,activation=None)
        - 对2D信号做最大池化层，使用MaxPooling2D(pool_size=(2,2))
        - Flatten层，使用Flatten进行创建
        - 全连接层，使用Dense(units,activation=None)进行创建
    - 损失函数和优化器的配置：model.compile(loss,optimizer='adam',matrics=['accuracy'])
    - 模型方法
        - fit函数进行训练
        - predict函数进行预测
        - evaluate函数对模型进行评估